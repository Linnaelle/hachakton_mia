# README - Fine-tuning d'un ModÃ¨le CNN pour la Reconnaissance Faciale

## Introduction
Ce projet porte sur le **fine-tuning d'un modÃ¨le CNN** afin d'amÃ©liorer la reconnaissance des Ã©motions faciales Ã  partir d'images. Il combine plusieurs Ã©tapes essentielles, notamment :
- **Le chargement et la fusion de datasets** (AffectNet & FER2013)
- **Le prÃ©traitement et la structuration des donnÃ©es**
- **Le fine-tuning d'un modÃ¨le CNN prÃ©-entraÃ®nÃ©**
- **L'entraÃ®nement en plusieurs phases pour une meilleure gÃ©nÃ©ralisation**
- **L'Ã©valuation et la visualisation des performances**

## 1. Installation des Packages NÃ©cessaires

Avant d'exÃ©cuter le projet, assurez-vous d'installer les dÃ©pendances suivantes :

```bash
pip install mtcnn lz4 tensorflow opencv-python numpy pandas seaborn torch torchvision facenet-pytorch keras
```

## 2. VÃ©rification du GPU

Le projet exploite la puissance du GPU pour accÃ©lÃ©rer l'entraÃ®nement. VÃ©rifiez la disponibilitÃ© du GPU avec :

```python
import tensorflow as tf
gpus = tf.config.list_physical_devices('GPU')
print("GPU disponibles :", gpus)
print("GPU utilisÃ© :", tf.test.gpu_device_name())
```

## 3. PrÃ©paration des DonnÃ©es

Le dataset **AffectNet** est tÃ©lÃ©chargÃ© et structurÃ© sous la forme suivante :

```
dataset_2/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 0 (neutral)
â”‚   â”œâ”€â”€ 1 (happy)
â”‚   â”œâ”€â”€ 2 (sad)
â”‚   â”œâ”€â”€ 3 (surprise)
â”‚   â”œâ”€â”€ 4 (fear)
â”‚   â”œâ”€â”€ 5 (disgust)
â”‚   â””â”€â”€ 6 (angry)
â””â”€â”€ val/
    â”œâ”€â”€ 0
    â”œâ”€â”€ 1
    â”œâ”€â”€ 2
    â”œâ”€â”€ 3
    â”œâ”€â”€ 4
    â”œâ”€â”€ 5
    â”œâ”€â”€ 6
```

Les images sont extraites et normalisÃ©es pour l'entraÃ®nement.

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1./255)
```

## 4. Chargement et Fine-Tuning du ModÃ¨le CNN

Nous chargeons un modÃ¨le CNN prÃ©-entraÃ®nÃ© (`best_model.h5`) et ajoutons de nouvelles couches pour affiner ses performances :

```python
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input

old_model = load_model('best_model.h5')
new_input = Input(shape=(48, 48, 1))

x = new_input
for layer in old_model.layers[:-1]:
    layer.trainable = False  # Geler les couches existantes
    x = layer(x)

x = Dense(256, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
new_output = Dense(7, activation='softmax')(x)

new_model = Model(new_input, new_output)
```

## 5. Compilation et EntraÃ®nement du ModÃ¨le

Nous entraÃ®nons le modÃ¨le en **deux phases** :
1. **Phase 1 :** Apprentissage des nouvelles couches avec la base gelÃ©e.
2. **Phase 2 :** Fine-tuning en dÃ©bloquant partiellement les couches du CNN.

```python
from tensorflow.keras.optimizers import Adam

# Phase 1 - Base gelÃ©e
new_model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])
history_phase1 = new_model.fit(train_generator, epochs=10, validation_data=val_generator)

# Phase 2 - Fine-tuning
for layer in old_model.layers[-4:]:
    layer.trainable = True
new_model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])
history_phase2 = new_model.fit(train_generator, epochs=20, validation_data=val_generator)
```

## 6. Visualisation des Performances

Nous affichons les courbes de **prÃ©cision et de perte** pour suivre l'Ã©volution de l'entraÃ®nement :

```python
import matplotlib.pyplot as plt

plt.plot(history_phase2.history['accuracy'], label='Train')
plt.plot(history_phase2.history['val_accuracy'], label='Validation')
plt.xlabel('Ã‰poques')
plt.ylabel('PrÃ©cision')
plt.legend()
plt.show()
```

## 7. Fusion des Datasets (AffectNet + FER2013)

Nous avons fusionnÃ© **AffectNet** et **FER2013** pour enrichir l'entraÃ®nement.

```python
import shutil

fer2013 = 'FER2013'
dataset2 = 'dataset_2'
nouveau_dataset = 'merged_dataset'
train_dir = os.path.join(nouveau_dataset, 'train')
test_dir = os.path.join(nouveau_dataset, 'test')

os.makedirs(train_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)
```

Les images de chaque catÃ©gorie sont copiÃ©es dans la nouvelle structure.

```python
def copier_images(src_dossier, dst_dossier):
    for filename in os.listdir(src_dossier):
        chemin_src = os.path.join(src_dossier, filename)
        chemin_dst = os.path.join(dst_dossier, filename)
        shutil.copy(chemin_src, chemin_dst)
```

AprÃ¨s fusion, nous crÃ©ons une **archive ZIP** du dataset final :

```bash
zip -r merged_dataset.zip merged_dataset
```

## 8. Sauvegarde et Exportation du ModÃ¨le Final

AprÃ¨s l'entraÃ®nement, nous sauvegardons le modÃ¨le affinÃ© pour une utilisation future :

```python
new_model.save('final_model_updated.h5')
```

## Conclusion

Ce projet illustre un **processus avancÃ© de fine-tuning d'un modÃ¨le CNN** en exploitant des bases de donnÃ©es enrichies pour amÃ©liorer la reconnaissance des Ã©motions faciales.

ğŸš€ **PrÃªt pour le dÃ©ploiement et l'utilisation en production !**

