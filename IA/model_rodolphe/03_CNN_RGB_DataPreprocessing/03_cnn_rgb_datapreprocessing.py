# -*- coding: utf-8 -*-
"""03_CNN_RGB_DataPreprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XO19lUvW6oziRTJRLFXnkUdIcb7mEkfp
"""



"""# Install package"""

!pip install tensorflow

!pip install kagglehub

!pip install insightface onnxruntime-gpu opencv-python numpy torch torchvision

!pip install opencv-python

!pip install facenet-pytorch

!pip install retina-face

!pip install tea

!pip install --upgrade retinaface



"""# Compile OpneCV"""

!apt-get update
!apt-get install -y build-essential cmake git pkg-config libgtk-3-dev libavcodec-dev libavformat-dev libswscale-dev
!apt-get install -y python3-dev python3-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-dev
!apt-get install -y libv4l-dev v4l-utils

!git clone https://github.com/opencv/opencv.git
!git clone https://github.com/opencv/opencv_contrib.git

!mkdir -p opencv/build
!cd opencv/build && cmake -D CMAKE_BUILD_TYPE=RELEASE \
    -D CMAKE_INSTALL_PREFIX=/usr/local \
    -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \
    -D WITH_CUDA=ON \
    -D ENABLE_FAST_MATH=1 \
    -D CUDA_FAST_MATH=1 \
    -D WITH_CUBLAS=1 \
    -D OPENCV_DNN_CUDA=ON \
    -D CUDA_ARCH_BIN="8.0" \
    -D BUILD_opencv_python3=ON ..

!cd opencv/build && make -j$(nproc)

!cd opencv/build && sudo make install && sudo ldconfig

"""# Compile Retina Face"""

#!git clone https://github.com/biubug6/Face-Detector-1MB-with-landmark.git
!python /content/RetinaFace/detect.py --trained_model /content/RetinaFace/weights/mobilenet0.25_Final.pth --network mobile0.25

"""# Download dataset and unzip"""

import kagglehub
!kaggle datasets download lintongdai/affectnet7 -p /content/affectnet7

!unzip -q /content/affectnet7/affectnet7.zip -d /content/affectnet

import shutil
import os

dossier_a_supprimer = "affectnet7"

# Vérifier si le dossier existe avant de le supprimer
if os.path.exists(dossier_a_supprimer):
    shutil.rmtree(dossier_a_supprimer)
    print(f"Le dossier '{dossier_a_supprimer}' et son contenu ont été supprimés avec succès.")
else:
    print(f"Le dossier '{dossier_a_supprimer}' n'existe pas.")

"""## Download and save into google drive for persitance"""

# from google.colab import drive
# drive.mount('/content/drive')

# !kaggle datasets download -d lintongdai/affectnet7 -p "/content/drive/MyDrive/AffectNet7"
# !unzip "/content/drive/MyDrive/AffectNet7/affectnet7.zip" -d "/content/affectnet7_extracted"

"""# Import package"""

import cv2
import os
import kagglehub
import zipfile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import tensorflow as tf

import torch
torch.cuda.is_available()

!nvidia-smi

# Vérifie pour voire si OpenCv est compiler sur le cuda
import cv2
print("WITH_CUDA :", cv2.getBuildInformation().find("CUDA"))

# SAvoir e nombre de cuda mon gpu dispose
import torch
print(torch.cuda.get_device_capability())

"""# Analyse data and classification

### Extraction du csv pour la comprehension
"""

# Upload the CSV file containing the annotations
df = pd.read_csv('/content/affectnet/affectnet.csv')

# Display the first rows of the DataFrame
print("Aperçu des données :")
print(df.head())

# Display general information about the DataFrame
print("\nInformations générales :")
print(df.info())

# Show the distribution of emotion labels
print("\nRépartition des labels d'émotions :")
print(df['label'].value_counts())

def afficher_arborescence(dossier, niveau=0, profondeur_max=2):
    """ Affiche l'arborescence des sous-dossiers jusqu'à profondeur_max, sans afficher les fichiers """
    if not os.path.exists(dossier):
        print("Le dossier spécifié n'existe pas.")
        return

    items = sorted(os.listdir(dossier))
    indent = "│   " * niveau

    for i, item in enumerate(items):
        chemin = os.path.join(dossier, item)
        est_dernier = (i == len(items) - 1)
        prefixe = "└── " if est_dernier else "├── "

        # Afficher uniquement les dossiers
        if os.path.isdir(chemin):
            print(indent + prefixe + item)

            # Limite la profondeur d'affichage des sous-dossiers
            if niveau < profondeur_max:
                afficher_arborescence(chemin, niveau + 1, profondeur_max)

# Spécifier le chemin du dossier à afficher
chemin_dossier = "affectnet/"
afficher_arborescence(chemin_dossier)

import os
import matplotlib.pyplot as plt

def compter_images_par_sous_dossier(racine, extensions_images=(".jpg", ".jpeg", ".png", ".bmp", ".gif")):
    """Compte le nombre d'images dans chaque sous-dossier."""
    stats_images = {}

    for dossier_principal in os.listdir(racine):
        chemin_principal = os.path.join(racine, dossier_principal)
        if os.path.isdir(chemin_principal):
            for sous_dossier in os.listdir(chemin_principal):
                chemin_sous_dossier = os.path.join(chemin_principal, sous_dossier)
                if os.path.isdir(chemin_sous_dossier):
                    count_images = sum(1 for f in os.listdir(chemin_sous_dossier) if f.lower().endswith(extensions_images))
                    stats_images[f"{dossier_principal}/{sous_dossier}"] = count_images

    return stats_images

def afficher_graphique_images(stats_images):
    """Affiche un graphique montrant le nombre d'images par sous-dossier."""
    dossiers = list(stats_images.keys())
    nb_images = list(stats_images.values())

    plt.figure(figsize=(12, 6))
    plt.barh(dossiers, nb_images, color="skyblue")
    plt.xlabel("Nombre d'images")
    plt.ylabel("Sous-dossiers")
    plt.title("Nombre d'images par sous-dossier")
    plt.xticks(rotation=45)
    plt.grid(axis='x', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.show()

# le chemin du dossier racine
chemin_racine = "affectnet/"

# Vérification si le dossier existe avant d'exécuter le script
if os.path.exists(chemin_racine):
    stats = compter_images_par_sous_dossier(chemin_racine)
    afficher_graphique_images(stats)
else:
    print(f"Le dossier '{chemin_racine}' n'existe pas.")

# Dossier de base contenant les sous-dossiers par label
base_dir = 'affectnet/train/'

# Lister les dossiers (étiquettes)
categories = sorted(os.listdir(base_dir))
print("Catégories trouvées :", categories)

plt.figure(figsize=(15, 8))

for i, category in enumerate(categories):
    # Chemin complet du sous-dossier
    category_path = os.path.join(base_dir, category)

    # Lister les fichiers dans le dossier
    images_list = os.listdir(category_path)

    # Vérifier qu'il y a au moins une image
    if len(images_list) == 0:
        print(f"Aucune image trouvée dans {category_path}")
        continue

    # Sélectionner la première image (vous pouvez aussi choisir aléatoirement)
    image_file = images_list[0]
    image_path = os.path.join(category_path, image_file)

    # Charger l'image
    img = mpimg.imread(image_path)

    # Afficher l'image dans une sous-figure
    plt.subplot(2, 4, i+1)
    plt.imshow(img, cmap='gray')
    plt.title(category)
    plt.axis('off')

plt.tight_layout()
plt.show()

# Chemin de base où se trouvent les dossiers (0, 1, …, 6)
base_dir = 'affectnet/train/'

# Parcourir chaque sous-dossier (catégorie)
for category in sorted(os.listdir(base_dir)):
    category_path = os.path.join(base_dir, category)
    if os.path.isdir(category_path):
        print(f"\nCatégorie {category}:")
        # Lister les images et limiter à 10
        image_files = sorted(os.listdir(category_path))[:10]
        for image_name in image_files:
            image_path = os.path.join(category_path, image_name)
            try:
                # Charger l'image et obtenir ses dimensions
                img = mpimg.imread(image_path)
                print(f"  Image : {image_name} - Dimensions : {img.shape}")
            except Exception as e:
                print(f"  Erreur avec {image_name} : {e}")

"""### Image processing"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Répertoire source contenant les sous-dossiers (par exemple : '0', '1', …, '6')
base_dir = 'affectnet/train/'

# Charger le classificateur Haar pour la détection de visage
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def crop_with_margin(gray, face_coords, margin_factor=0.3):
    """
    Recadre l'image en ajoutant une marge autour du visage.
    margin_factor détermine la proportion de marge ajoutée.
    """
    x, y, w, h = face_coords
    img_h, img_w = gray.shape
    margin_x = int(w * margin_factor)
    margin_y = int(h * margin_factor)
    new_x = max(0, x - margin_x)
    new_y = max(0, y - margin_y)
    new_w = min(img_w - new_x, w + 2 * margin_x)
    new_h = min(img_h - new_y, h + 2 * margin_y)
    return gray[new_y:new_y+new_h, new_x:new_x+new_w]

processed_images = []
titles = []

# Parcourir chaque sous-dossier
for category in sorted(os.listdir(base_dir)):
    category_path = os.path.join(base_dir, category)
    if not os.path.isdir(category_path):
        continue
    image_files = sorted(os.listdir(category_path))
    if not image_files:
        print(f"Aucune image trouvée dans {category_path}")
        continue

    # Prendre la première image du dossier
    image_file = image_files[0]
    image_path = os.path.join(category_path, image_file)

    # Charger l'image en couleur puis en niveaux de gris
    img = cv2.imread(image_path)
    if img is None:
        print(f"Erreur de chargement de l'image {image_path}")
        continue
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Détection du visage
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)
    if len(faces) == 0:
        # Aucun visage détecté, utiliser l'image entière
        cropped = gray
    else:
        # Sélectionner le visage le plus grand
        faces = sorted(faces, key=lambda r: r[2]*r[3], reverse=True)
        face = faces[0]
        cropped = crop_with_margin(gray, face, margin_factor=0.3)

    # Redimensionner l'image recadrée à 48x48 pixels
    resized = cv2.resize(cropped, (48, 48))

    processed_images.append(resized)
    titles.append(f"Catégorie {category}")

# Afficher toutes les images en grille avec la mention "48x48" en dessous de chaque image
num_images = len(processed_images)
cols = 2
rows = (num_images + cols - 1) // cols

plt.figure(figsize=(cols * 4, rows * 4))
for i, (img, title) in enumerate(zip(processed_images, titles)):
    ax = plt.subplot(rows, cols, i + 1)
    plt.imshow(img, cmap='gray')
    plt.title(title)
    # On masque les ticks tout en ajoutant un label sous l'image
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_xlabel("48x48", fontsize=10)
plt.tight_layout()
plt.show()

import tensorflow as tf
tf.config.run_functions_eagerly(True)

import tensorflow as tf
print(tf.__version__)

# Telechargement du model
from retinaface import RetinaFace
rf_model = RetinaFace.build_model()
print("Modèle RetinaFace chargé.")

import os
import cv2
import torch
import numpy as np
import time
from concurrent.futures import ThreadPoolExecutor
from torchvision import transforms
from PIL import Image
from facenet_pytorch import MTCNN

# --------------------------------------------------
# Configuration du périphérique (GPU si disponible)
# --------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Utilisation du périphérique : {device}")

# --------------------------------------------------
# Initialisation du détecteur de visage MTCNN (PyTorch)
# --------------------------------------------------
mtcnn = MTCNN(keep_all=True, device=device)

# --------------------------------------------------
# Transformation pour redimensionner et convertir en niveaux de gris
# --------------------------------------------------
transform = transforms.Compose([
    transforms.ToPILImage(),       # Convertir le tableau numpy en image PIL
    transforms.Grayscale(),        # Conversion en niveaux de gris
    transforms.Resize((48, 48)),   # Redimensionner à 48x48 pixels
    transforms.ToTensor()          # Convertir en Tensor (valeurs entre 0 et 1)
])

# --------------------------------------------------
# Fonction de recadrage avec marge
# --------------------------------------------------
def crop_with_margin(image, bbox, margin=0.3):
    """
    Recadre l'image autour de la boîte englobante (bbox: [x1, y1, x2, y2])
    en y ajoutant une marge.
    """
    x1, y1, x2, y2 = bbox.astype(int)
    w, h = x2 - x1, y2 - y1
    margin_x = int(w * margin)
    margin_y = int(h * margin)
    new_x1 = max(0, x1 - margin_x)
    new_y1 = max(0, y1 - margin_y)
    new_x2 = min(image.shape[1], x2 + margin_x)
    new_y2 = min(image.shape[0], y2 + margin_y)
    return image[new_y1:new_y2, new_x1:new_x2]

# --------------------------------------------------
# Détection et recadrage du visage avec MTCNN
# --------------------------------------------------
def detect_and_crop(image_path, margin=0.3):
    """
    Charge l'image, détecte les visages avec MTCNN et recadre l'image
    autour du visage le plus grand en y ajoutant une marge.
    Retourne l'image recadrée (format RGB) ou None en cas d'échec.
    """
    # Charger l'image et la convertir en RGB
    img = cv2.imread(image_path)
    if img is None:
        print(f"Erreur de chargement de l'image: {image_path}")
        return None
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Détection des visages avec MTCNN
    boxes, _ = mtcnn.detect(img_rgb)
    if boxes is None or len(boxes) == 0:
        print(f"Aucun visage détecté dans {image_path}")
        return None

    # Sélectionner la boîte ayant la plus grande surface
    boxes = np.array(boxes)
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    best_idx = np.argmax(areas)
    best_box = boxes[best_idx]

    # Recadrage avec marge
    cropped = crop_with_margin(img_rgb, best_box, margin=margin)
    return cropped

# --------------------------------------------------
# Traitement complet d'une image
# --------------------------------------------------
def process_image_file(input_path, output_path):
    """
    Détecte et recadre le visage, redimensionne l'image en 48x48 pixels,
    convertit en niveaux de gris et sauvegarde le résultat.
    """
    cropped = detect_and_crop(input_path, margin=0.3)
    if cropped is None:
        print(f"Échec ou aucun visage pour {input_path}")
        return False

    # Redimensionnement à 48x48 pixels
    resized = cv2.resize(cropped, (48, 48))

    # Appliquer la transformation (niveaux de gris, tensor)
    tensor = transform(resized)
    processed_img = (tensor.squeeze().cpu().numpy() * 255).astype(np.uint8)

    # Sauvegarde de l'image traitée
    if not cv2.imwrite(output_path, processed_img):
        print(f"Erreur lors de l'écriture de {output_path}")
        return False

    print(f"Image sauvegardée : {output_path}")
    return True

# --------------------------------------------------
# Wrapper pour le traitement parallèle
# --------------------------------------------------
def process_wrapper(task):
    input_path, output_path = task
    return process_image_file(input_path, output_path)

# --------------------------------------------------
# Découpage de la liste en lots (chunks)
# --------------------------------------------------
def chunker(seq, size):
    for pos in range(0, len(seq), size):
        yield seq[pos:pos + size]

# --------------------------------------------------
# Traitement en lots d'un répertoire d'images
# --------------------------------------------------
def process_category_in_batches(input_category_dir, output_category_dir, batch_size=50, max_workers=4):
    os.makedirs(output_category_dir, exist_ok=True)
    tasks = []
    valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')
    for filename in sorted(os.listdir(input_category_dir)):
        if not filename.lower().endswith(valid_exts):
            continue
        in_path = os.path.join(input_category_dir, filename)
        out_path = os.path.join(output_category_dir, filename)
        if os.path.exists(out_path):
            print(f"Déjà traité : {out_path}")
            continue
        tasks.append((in_path, out_path))

    total_tasks = len(tasks)
    print(f"Nombre total d'images à traiter dans {input_category_dir} : {total_tasks}")
    batch_number = 1
    total_processed = 0
    total_failed = 0

    for batch in chunker(tasks, batch_size):
        print(f"Traitement du lot {batch_number} contenant {len(batch)} images...")
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            results = list(executor.map(process_wrapper, batch))
        succeeded = sum(results)
        failed = len(batch) - succeeded
        total_processed += succeeded
        total_failed += failed
        print(f"[Lot {batch_number}] Succès : {succeeded}, Échecs : {failed}\n")
        batch_number += 1

    print(f"Traitement complet terminé pour {input_category_dir}")
    print(f"Total traité avec succès : {total_processed}, échoués : {total_failed}")

# --------------------------------------------------
# Utilitaire de comptage d'images
# --------------------------------------------------
def count_images(folder_path, extensions=('.jpg', '.jpeg', '.png', '.bmp')):
    return sum(1 for file in os.listdir(folder_path) if file.lower().endswith(extensions))

# --------------------------------------------------
# Point d'entrée principal
# --------------------------------------------------
if __name__ == "__main__":
    # Exemple : traitement de la classe "6" dans le sous-dossier "train" du dataset "affectnet"
    input_base = 'affectnet'
    output_base = 'affectnet_processed_pytorch'
    subset = 'train'
    category = '1'

    input_category_dir = os.path.join(input_base, subset, category)
    output_category_dir = os.path.join(output_base, subset, category)

    print("Chemin d'entrée absolu :", os.path.abspath(input_category_dir))
    print("Chemin de sortie absolu :", os.path.abspath(output_category_dir))

    # Paramètres du batch en fonction de la mémoire GPU
    batch_size = 200
    max_workers = 16
    if torch.cuda.is_available():
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        print(f"Mémoire GPU disponible : {gpu_mem:.2f} GB")
        if gpu_mem > 10:
            batch_size, max_workers = 512, 256
        elif gpu_mem > 6:
            batch_size, max_workers = 50, 6
        else:
            batch_size, max_workers = 30, 4
    else:
        batch_size, max_workers = 20, 4

    print(f"Utilisation de batch_size={batch_size} et max_workers={max_workers}")

    start_time = time.time()
    process_category_in_batches(input_category_dir, output_category_dir, batch_size, max_workers)
    end_time = time.time()

    print(f"Traitement terminé en {end_time - start_time:.2f} secondes.")
    num_images = count_images(output_category_dir)
    print(f"Nombre total d'images traitées dans {output_category_dir} : {num_images}")

import os

def count_images(folder_path, extensions=['.jpg', '.jpeg', '.png', '.bmp']):
    """
    Compte le nombre de fichiers dans folder_path qui ont une extension dans la liste extensions.
    """
    count = 0
    for file in os.listdir(folder_path):
        if any(file.lower().endswith(ext) for ext in extensions):
            count += 1
    return count

# Exemple d'utilisation
folder = 'affectnet_processed_parallel/train/1'
num_images = count_images(folder)
print(f"Nombre d'images dans {os.path.abspath(folder)} : {num_images}")

"""## Save Traitelent Data

### Zip file
"""

import os
import shutil

def zipper_dossier(dossier_source, dossier_zip):
    """
    Crée une archive ZIP du dossier spécifié.

    :param dossier_source: Chemin du dossier à compresser.
    :param dossier_zip: Chemin de l'archive ZIP de sortie (sans l'extension .zip).
    """
    if not os.path.exists(dossier_source):
        print(f"Le dossier '{dossier_source}' n'existe pas.")
        return

    shutil.make_archive(dossier_zip, 'zip', dossier_source)
    print(f"Archive créée : {dossier_zip}.zip")

# Spécifier le dossier de sortie après traitement
dossier_a_zipper = "affectnet_processed_pytorch"
dossier_zip_sortie = "affectnet_processed_pytorch_compressed"

# Vérifier si le dossier existe avant de le zipper
if os.path.exists(dossier_a_zipper):
    zipper_dossier(dossier_a_zipper, dossier_zip_sortie)
else:
    print(f"Le dossier '{dossier_a_zipper}' n'est pas encore disponible. Assurez-vous que le traitement est terminé.")

from google.colab import drive
drive.mount('/content/drive')

import shutil

# Chemin du fichier ZIP généré
fichier_zip = "affectnet_processed_pytorch_compressed.zip"

# Destination sur Google Drive (dans "My Drive")
destination_drive = "/content/drive/MyDrive/Colab Notebooks" + fichier_zip

# Copier le fichier vers Google Drive
shutil.move(fichier_zip, destination_drive)

print(f"Le fichier {fichier_zip} a été sauvegardé dans Google Drive : {destination_drive}")

# Dictionnaire des émotions basées sur AffectNet
emotion_dict = {
    0: "neutral",
    1: "happy",
    2: "sad",
    3: "surprise",
    4: "fear",
    5: "disgust",
    6: "angry"
}

# Fonction pour afficher une image avec son label
def afficher_image(index):
    chemin_image = df.loc[index, 'img_path']  # Chemin de l'image
    label = df.loc[index, 'label']  # Label d'émotion

    # Charger l'image
    image = cv2.imread(chemin_image)
    if image is None:
        print(f"Image introuvable : {chemin_image}")
        return

    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convertir en RGB

    # Afficher l'image
    plt.imshow(image_rgb)
    plt.title(f"Émotion : {emotion_dict.get(label, 'Inconnu')}")
    plt.axis('off')
    plt.show()

# Afficher un exemple pour chaque catégorie
for label in df['label'].unique():
    index = df[df['label'] == label].index[0]  # Trouver un index avec ce label
    afficher_image(index)

